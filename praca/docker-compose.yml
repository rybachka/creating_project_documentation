# docker-compose.yml
services:
  java-api:
    build:
      context: ./java-api
    image: praca/java-api:dev
    container_name: java-api
    expose:
      - "8080"
    volumes:
      - ./snapshots:/snapshots
      - uploads:/uploads

  python-nlp:
    build: ./python-nlp
    image: praca/python-nlp:dev
    container_name: python-nlp
    expose:
      - "8000"
    environment:
      NLP_MODE: "ollama"
      OLLAMA_BASE_URL: "http://host.docker.internal:11434"
      OLLAMA_MODEL: "llama3.1:8b-instruct-q4_K_M"
      # Parametry generacji (bazowe)
      OLLAMA_TEMPERATURE: "0.3"
      OLLAMA_TOP_P: "0.9"
      OLLAMA_TOP_K: "60"
      OLLAMA_REPEAT_PENALTY: "1.15"
      OLLAMA_NUM_CTX: "4096"
      OLLAMA_NUM_PREDICT: "256"
      NLP_DEBUG: "true"
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/healthz', timeout=3)"]
      interval: 15s
      timeout: 5s
      retries: 20
      start_period: 45s

  web:
    build:
      context: ./web-ui
    image: praca/web:dev
    container_name: web
    ports:
      - "8080:80"
    depends_on:
      java-api:
        condition: service_started
      python-nlp:
        condition: service_healthy

volumes:
  uploads: {}
