# docker-compose.yml
services:
  java-api:
    build:
      context: ./java-api
    image: praca/java-api:dev
    container_name: java-api
    expose:
      - "8080"
    volumes:
      - ./snapshots:/snapshots
      - uploads:/uploads

  python-nlp:
    build:
      context: ./python-nlp
    image: praca/python-nlp:dev
    container_name: python-nlp
    expose:
      - "8000"
    environment:
      NLP_ENABLE_MT5: "true"
      NLP_WARMUP: "false"
      # ➜ przełączamy na instruction-tuned model
      MT5_MODEL_NAME: "google/flan-t5-base"
      # ➜ stabilniejsza generacja
      MT5_NUM_BEAMS: "8"
      # ➜ zostawiamy tylko MED/RET (short/long ignorowane przez serwer – niewadzą)
      MT5_MAX_TOK_SHORT: "48"
      MT5_MAX_TOK_MED: "200"
      MT5_MAX_TOK_LONG: "140"
      MT5_MAX_TOK_RET: "80"
      MT5_TASK_PREFIX: ""          # bez prefiksu (lepiej dla FLAN/T5-instruct)
      NLP_DEBUG: "true"            # diagnostyka w logach
      TOKENIZERS_PARALLELISM: "false"
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/healthz', timeout=3)"]
      interval: 20s
      timeout: 5s
      retries: 20
      start_period: 60s

  web:
    build:
      context: ./web-ui
    image: praca/web:dev
    container_name: web
    ports:
      - "8080:80"
    depends_on:
      java-api:
        condition: service_started
      python-nlp:
        condition: service_healthy

volumes:
  uploads: {}
